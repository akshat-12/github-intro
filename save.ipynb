{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YearsInCurrentRole        -0.269408\n",
       "TotalWorkingYears         -0.262922\n",
       "MonthlyIncome             -0.240479\n",
       "YearsAtCompany            -0.230061\n",
       "YearsWithCurrManager      -0.222752\n",
       "Age                       -0.200596\n",
       "StockOptionLevel          -0.175496\n",
       "JobInvolvement            -0.159710\n",
       "JobSatisfaction           -0.148012\n",
       "EnvironmentSatisfaction   -0.111746\n",
       "TrainingTimesLastYear     -0.105663\n",
       "EmployeeNumber            -0.051512\n",
       "YearsSinceLastPromotion   -0.050379\n",
       "Education                 -0.041390\n",
       "PercentSalaryHike         -0.012668\n",
       "PerformanceRating          0.010202\n",
       "NumCompaniesWorked         0.034763\n",
       "CommunicationSkill         0.103379\n",
       "DistanceFromHome           0.109224\n",
       "Id                         0.694838\n",
       "Attrition                  1.000000\n",
       "Behaviour                       NaN\n",
       "Name: Attrition, dtype: float64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()[\"Attrition\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BusinessTravel'] = labelencoder.fit_transform(df['BusinessTravel'])\n",
    "df['Department'] = labelencoder.fit_transform(df['Department'])\n",
    "df['EducationField'] = labelencoder.fit_transform(df['EducationField'])\n",
    "df['Gender'] = labelencoder.fit_transform(df['Gender'])\n",
    "df['JobRole'] = labelencoder.fit_transform(df['JobRole'])\n",
    "df['MaritalStatus'] = labelencoder.fit_transform(df['MaritalStatus'])\n",
    "df['OverTime'] = labelencoder.fit_transform(df['OverTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Id', 'Behaviour', 'EmployeeNumber', 'Gender', 'PercentSalaryHike', 'PerformanceRating'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2 = train_test_split(df, train_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df1.drop('Attrition', axis = 1)\n",
    "y_train = df1['Attrition']\n",
    "X_val = df2.drop(\"Attrition\", axis = 1)\n",
    "y_val = df2['Attrition']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 2, 3, 5, 10],\n",
    "        'gamma': [0.1, 0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [6, 7, 8, 9 ,10]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=2000, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "param_comb = 200\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=1001 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed: 18.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x00000233300E2348>,\n",
       "                   error_score=nan,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           learning_rate=0.02, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=2000,\n",
       "                                           n_jobs=1, nthread=1,\n",
       "                                           objective='binary:l...\n",
       "                                           seed=None, silent=True, subsample=1,\n",
       "                                           verbosity=1),\n",
       "                   iid='deprecated', n_iter=200, n_jobs=4,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.1, 0.5, 1, 1.5, 2, 5],\n",
       "                                        'max_depth': [6, 7, 8, 9, 10],\n",
       "                                        'min_child_weight': [1, 2, 3, 5, 10],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=1001, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([11.10484958, 11.1713738 , 11.10584049,  2.90823269,  3.64565344,\n",
      "        6.51561661,  3.75655699,  3.47590666,  5.51665187,  5.43866053,\n",
      "        6.14357681,  6.51897001,  3.30935378,  4.79319386,  3.74359093,\n",
      "        6.96218705,  2.61121907,  5.52642708,  2.7915452 ,  3.8038383 ,\n",
      "        5.22622027,  3.09971266,  2.80730247,  3.87046075,  6.00893636,\n",
      "        3.13362141,  4.20755177,  2.9920001 ,  6.75474215,  5.22702565,\n",
      "        3.81501064,  5.5182487 ,  2.99918137,  4.14930763,  6.23672752,\n",
      "        3.49186511,  3.56287389,  2.87831421,  4.35177741,  4.79657707,\n",
      "        3.7212523 ,  4.13674097,  4.36413312,  5.56631908,  4.07370925,\n",
      "        4.72876   ,  2.89107122,  4.21652732,  5.53021622,  3.15616088,\n",
      "        5.57070751,  3.59718356,  3.45596833,  4.42157946,  3.1958488 ,\n",
      "        3.53715429,  3.21400714,  5.54018884,  4.41619411,  3.01374249,\n",
      "        8.12234459,  4.94066315,  5.72272611,  3.41114783,  4.18880095,\n",
      "        3.54592028,  2.7189311 ,  3.30575213,  2.91660228,  3.2945919 ,\n",
      "        4.09645882,  3.35262346,  2.44586954,  3.53575029,  6.4134541 ,\n",
      "        4.25203328,  4.2175251 ,  3.94526191,  3.15117617,  3.18608255,\n",
      "        3.79226203,  3.06101437,  3.80822906,  4.39764385,  6.30296636,\n",
      "        4.41060815,  3.76293406,  2.45722232,  5.71432462,  3.32291613,\n",
      "        3.85051446,  4.07769837,  3.92551436,  5.41094084,  3.31114845,\n",
      "        4.0878716 ,  4.32863665,  4.88035359,  3.2688612 ,  4.83228092,\n",
      "        2.73030224,  3.98335147,  3.61074538,  5.02975655,  3.83915009,\n",
      "        3.33888097,  3.34764857,  3.55250063,  3.96539888,  4.04754524,\n",
      "        3.29519963,  5.05707998,  3.79108295,  3.23834257,  4.05955582,\n",
      "        4.65535665,  2.75124431,  4.36852007,  5.41494527,  3.3539793 ,\n",
      "        5.69996195,  5.1640018 ,  5.78692861,  4.25642047,  4.9066823 ,\n",
      "        2.82883801,  4.4499023 ,  6.61470838,  4.01486645,  3.83774719,\n",
      "        5.25708413,  3.21261249,  4.1741776 ,  3.89798651,  3.07039261,\n",
      "        5.88128543,  3.29719491,  2.47358074,  3.7647439 ,  4.5197175 ,\n",
      "        3.11706634,  3.07098918,  3.69823837,  3.73800731,  2.9277751 ,\n",
      "        7.15626845,  3.80502768,  3.11687446,  3.23495073,  3.85350618,\n",
      "        4.38986211,  4.27717285,  3.72564058,  2.7368834 ,  4.79120307,\n",
      "        4.87817626,  3.62470293,  3.77270312,  3.87002029,  4.38084149,\n",
      "        5.99775367,  7.46901579,  4.34937344,  4.39784346,  3.62990499,\n",
      "        5.83101153,  3.40728946,  3.16913528,  6.03447652,  2.85297174,\n",
      "        2.78914337,  4.06812444,  3.5473166 ,  4.15768542,  3.34986358,\n",
      "        3.60037532,  3.17392526,  6.85287104,  5.65548964,  3.58780842,\n",
      "        2.74387221,  4.54225731,  4.70043473,  3.8636713 ,  4.40981932,\n",
      "        3.25171471,  4.9691246 ,  5.04091978,  5.82105937,  3.15955124,\n",
      "        4.81472788,  3.76034794,  2.88049908,  5.10248327,  4.85013218,\n",
      "        3.03378849,  3.29233222,  3.16094952,  5.1067554 ,  4.83968043]), 'std_fit_time': array([0.119953  , 0.19157831, 1.71127039, 1.33910965, 0.24687496,\n",
      "       0.23721579, 0.15216328, 0.16587114, 0.18917921, 0.06829069,\n",
      "       0.31507775, 0.07218338, 0.1944935 , 0.09346418, 0.3536544 ,\n",
      "       0.16924437, 0.08420073, 0.19921336, 0.08641034, 0.06013484,\n",
      "       0.06635517, 0.05808254, 0.11289898, 0.05490801, 0.05402213,\n",
      "       0.02184076, 0.04301952, 0.08697493, 0.08429079, 0.02714604,\n",
      "       0.08061865, 0.10224282, 0.16843349, 0.13705176, 0.13459144,\n",
      "       0.09411566, 0.04154197, 0.04754683, 0.04929909, 0.05126205,\n",
      "       0.01973035, 0.07811742, 0.07281677, 0.07716666, 0.05354283,\n",
      "       0.03749747, 0.08381937, 0.16562331, 0.10123544, 0.05598843,\n",
      "       0.07167774, 0.08791742, 0.09428122, 0.03450573, 0.07195258,\n",
      "       0.08330102, 0.04099806, 0.21776876, 0.03584259, 0.06004368,\n",
      "       0.20755591, 0.08883497, 0.10171907, 0.02928927, 0.03536771,\n",
      "       0.11153876, 0.07931998, 0.06199709, 0.04838646, 0.04607909,\n",
      "       0.04124691, 0.04496   , 0.04651574, 0.09479862, 0.08659764,\n",
      "       0.04493308, 0.0727426 , 0.02254074, 0.04220263, 0.05665952,\n",
      "       0.08392946, 0.06245152, 0.03024681, 0.035962  , 0.03946939,\n",
      "       0.06001342, 0.04181153, 0.01671381, 0.05656046, 0.15241591,\n",
      "       0.07601877, 0.04161488, 0.12611365, 0.05551729, 0.08409191,\n",
      "       0.07361984, 0.05596376, 0.07488585, 0.05344447, 0.10363229,\n",
      "       0.06685684, 0.05567121, 0.08854353, 0.11232452, 0.04883536,\n",
      "       0.03072983, 0.04978044, 0.05865813, 0.08714421, 0.15723478,\n",
      "       0.0784565 , 0.03112412, 0.04676821, 0.04586556, 0.08361672,\n",
      "       0.2442894 , 0.03799596, 0.06559836, 0.07938819, 0.01067686,\n",
      "       0.08166954, 0.11336006, 0.04584531, 0.22098192, 0.04273492,\n",
      "       0.04306289, 0.04748434, 0.08482037, 0.01588896, 0.06242648,\n",
      "       0.07024029, 0.06189659, 0.03326693, 0.06721185, 0.02430103,\n",
      "       0.0355522 , 0.04199172, 0.02159851, 0.05654454, 0.04842323,\n",
      "       0.07304049, 0.05328154, 0.032153  , 0.1036311 , 0.03150436,\n",
      "       0.06717687, 0.03625407, 0.02065456, 0.06221508, 0.08820842,\n",
      "       0.05197889, 0.16492719, 0.08441901, 0.05891039, 0.03444761,\n",
      "       0.10699032, 0.05437109, 0.28184917, 0.04011367, 0.14990911,\n",
      "       0.10438518, 0.06587963, 0.05884725, 0.28284825, 0.04535314,\n",
      "       0.11954859, 0.05433704, 0.06460514, 0.25850579, 0.08541225,\n",
      "       0.03046438, 0.06788118, 0.05802133, 0.08098252, 0.0678786 ,\n",
      "       0.05112127, 0.06560962, 0.14745472, 0.05934822, 0.03054898,\n",
      "       0.06466895, 0.30843047, 0.28508235, 0.04401861, 0.07673563,\n",
      "       0.06745831, 0.07728816, 0.0910373 , 0.05017171, 0.05058953,\n",
      "       0.07451171, 0.08996095, 0.04260606, 0.37651134, 0.03665607,\n",
      "       0.03693252, 0.03549913, 0.06905205, 0.53135207, 0.30273338]), 'mean_score_time': array([0.05237842, 0.04066343, 0.01658607, 0.02573137, 0.01934905,\n",
      "       0.02393589, 0.0420887 , 0.0269289 , 0.02633014, 0.02313871,\n",
      "       0.01815195, 0.0203505 , 0.02752624, 0.02692056, 0.02493439,\n",
      "       0.0097743 , 0.02652988, 0.01396289, 0.01974082, 0.02113729,\n",
      "       0.01696725, 0.02932243, 0.0231308 , 0.02273183, 0.0177526 ,\n",
      "       0.02095289, 0.01256742, 0.02892356, 0.01695604, 0.01675701,\n",
      "       0.01475105, 0.01855111, 0.02373796, 0.0145618 , 0.01316528,\n",
      "       0.02992096, 0.01954837, 0.03070846, 0.01854   , 0.01436143,\n",
      "       0.02872367, 0.00917597, 0.02453489, 0.01156974, 0.03470769,\n",
      "       0.01894836, 0.03131657, 0.01556039, 0.01894331, 0.02273955,\n",
      "       0.01137028, 0.02852349, 0.01835017, 0.01276608, 0.03450794,\n",
      "       0.03190432, 0.02453532, 0.00977416, 0.01894917, 0.03291287,\n",
      "       0.00879383, 0.02175031, 0.0202702 , 0.02732754, 0.02672935,\n",
      "       0.02014627, 0.01954875, 0.02353797, 0.02493377, 0.03929496,\n",
      "       0.02194333, 0.01974912, 0.02153449, 0.0171598 , 0.01276608,\n",
      "       0.02134328, 0.02074518, 0.03230467, 0.02293901, 0.02433558,\n",
      "       0.01356444, 0.01535959, 0.02233925, 0.01216707, 0.01216807,\n",
      "       0.01575112, 0.0179522 , 0.02553344, 0.01396284, 0.0097784 ,\n",
      "       0.02652245, 0.01934776, 0.01535182, 0.01775341, 0.02573214,\n",
      "       0.03551393, 0.01973968, 0.01795158, 0.01974845, 0.0191494 ,\n",
      "       0.0159574 , 0.01256623, 0.01496215, 0.01934791, 0.02312493,\n",
      "       0.03850021, 0.02612176, 0.02353706, 0.0257319 , 0.02254162,\n",
      "       0.03210664, 0.01775374, 0.03349276, 0.02314763, 0.01973882,\n",
      "       0.01315689, 0.02374911, 0.01655622, 0.01534643, 0.02813344,\n",
      "       0.01616931, 0.0131577 , 0.01615915, 0.01236796, 0.01835814,\n",
      "       0.02054524, 0.02373714, 0.01575861, 0.01097093, 0.02254019,\n",
      "       0.01655574, 0.01159577, 0.01817856, 0.02712097, 0.02014623,\n",
      "       0.01097131, 0.02013054, 0.02414379, 0.02113495, 0.02114458,\n",
      "       0.01895018, 0.01976719, 0.01675673, 0.01496768, 0.02553458,\n",
      "       0.01236739, 0.03530669, 0.0227397 , 0.01137075, 0.00996656,\n",
      "       0.02473516, 0.01655717, 0.02932062, 0.02652965, 0.01017337,\n",
      "       0.01215968, 0.01436667, 0.01276703, 0.02633953, 0.02358961,\n",
      "       0.01138215, 0.01276698, 0.01695437, 0.01515946, 0.0205369 ,\n",
      "       0.02234044, 0.02712927, 0.01654768, 0.01216784, 0.02234054,\n",
      "       0.02014713, 0.01895728, 0.0307189 , 0.01337137, 0.02932291,\n",
      "       0.02912283, 0.02412415, 0.01017327, 0.01973987, 0.02774262,\n",
      "       0.02214112, 0.01476145, 0.01675353, 0.03351078, 0.02871695,\n",
      "       0.02791758, 0.0183423 , 0.01675882, 0.01972699, 0.03489819,\n",
      "       0.01995521, 0.03190842, 0.0241365 , 0.01278362, 0.02861962,\n",
      "       0.02506781, 0.02214103, 0.02833209, 0.01875072, 0.01216578]), 'std_score_time': array([0.00179041, 0.00412141, 0.00655238, 0.00324055, 0.00079765,\n",
      "       0.00189198, 0.00844892, 0.00274917, 0.00370987, 0.00146595,\n",
      "       0.00311662, 0.00306968, 0.00264669, 0.00384643, 0.00351163,\n",
      "       0.00159557, 0.00325289, 0.00166744, 0.00247109, 0.00116383,\n",
      "       0.00225962, 0.0027203 , 0.00247028, 0.00222039, 0.00347728,\n",
      "       0.00226738, 0.00135304, 0.00267651, 0.00109288, 0.00132328,\n",
      "       0.001714  , 0.00312755, 0.00212926, 0.00079776, 0.00277958,\n",
      "       0.00484541, 0.00256947, 0.00406928, 0.00184702, 0.00173883,\n",
      "       0.0023089 , 0.00116312, 0.00195399, 0.00205396, 0.00159468,\n",
      "       0.00124941, 0.00499032, 0.00214747, 0.00303067, 0.00193407,\n",
      "       0.00184969, 0.0033731 , 0.00232558, 0.00159552, 0.0035459 ,\n",
      "       0.00611722, 0.00439715, 0.00039897, 0.00227425, 0.0055345 ,\n",
      "       0.00191833, 0.00284363, 0.00224582, 0.00286309, 0.00203413,\n",
      "       0.00171558, 0.00149222, 0.00135257, 0.00178315, 0.00396995,\n",
      "       0.00140929, 0.00146575, 0.00223356, 0.00203931, 0.00212996,\n",
      "       0.00223837, 0.00193434, 0.00294741, 0.00178526, 0.00184867,\n",
      "       0.00135264, 0.00185018, 0.00163646, 0.00097785, 0.00074619,\n",
      "       0.0015893 , 0.00189188, 0.00135195, 0.00089207, 0.00132354,\n",
      "       0.00204811, 0.00205359, 0.0027852 , 0.00159604, 0.00277807,\n",
      "       0.00380873, 0.00298841, 0.00218392, 0.00182764, 0.00203419,\n",
      "       0.00209183, 0.00135202, 0.00179405, 0.00241289, 0.0023853 ,\n",
      "       0.00225213, 0.00192609, 0.0018502 , 0.004342  , 0.00280796,\n",
      "       0.0031891 , 0.00193375, 0.00232901, 0.00262838, 0.00211603,\n",
      "       0.00171234, 0.00193955, 0.00205297, 0.00050011, 0.00255362,\n",
      "       0.00158671, 0.00171669, 0.00132409, 0.00162156, 0.00206466,\n",
      "       0.00184812, 0.00247424, 0.00171569, 0.00209226, 0.00100078,\n",
      "       0.0016209 , 0.00185714, 0.00284647, 0.00115721, 0.00182836,\n",
      "       0.00089228, 0.00238753, 0.00269288, 0.00248364, 0.00255338,\n",
      "       0.00267639, 0.00170328, 0.00116143, 0.00226622, 0.00204846,\n",
      "       0.00214751, 0.00232594, 0.00317864, 0.00232551, 0.00199862,\n",
      "       0.0020329 , 0.00205355, 0.00312797, 0.00349021, 0.00203316,\n",
      "       0.00146126, 0.00299454, 0.00193285, 0.00348899, 0.00261454,\n",
      "       0.00136777, 0.0015959 , 0.00178409, 0.00097702, 0.00233587,\n",
      "       0.00101809, 0.00222151, 0.00279744, 0.0014708 , 0.00184997,\n",
      "       0.00263135, 0.00281007, 0.00074619, 0.00249838, 0.0025683 ,\n",
      "       0.00182805, 0.00330236, 0.00171585, 0.00132201, 0.00145135,\n",
      "       0.00159554, 0.00159627, 0.00074288, 0.00184873, 0.00312102,\n",
      "       0.00110004, 0.00299667, 0.00169832, 0.00270892, 0.00320894,\n",
      "       0.00268589, 0.00245287, 0.0014656 , 0.00220722, 0.00207767,\n",
      "       0.00213773, 0.00270554, 0.00204053, 0.00159547, 0.00231141]), 'param_subsample': masked_array(data=[0.8, 0.8, 0.6, 0.6, 0.8, 0.6, 0.6, 1.0, 0.6, 0.6, 1.0,\n",
      "                   0.8, 1.0, 0.6, 0.8, 1.0, 0.6, 1.0, 0.8, 0.8, 0.8, 0.8,\n",
      "                   0.6, 1.0, 0.8, 0.8, 1.0, 0.8, 0.6, 0.8, 1.0, 0.6, 0.6,\n",
      "                   1.0, 0.8, 0.8, 0.8, 1.0, 0.8, 0.6, 0.6, 1.0, 0.6, 1.0,\n",
      "                   0.6, 0.6, 1.0, 1.0, 0.8, 1.0, 0.8, 0.6, 0.8, 1.0, 0.6,\n",
      "                   1.0, 0.8, 1.0, 0.6, 0.6, 1.0, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
      "                   1.0, 0.6, 1.0, 0.8, 0.8, 1.0, 0.6, 1.0, 0.6, 0.6, 0.8,\n",
      "                   0.6, 0.6, 0.8, 1.0, 1.0, 0.8, 0.8, 1.0, 0.8, 0.8, 0.6,\n",
      "                   0.6, 1.0, 0.6, 0.8, 1.0, 0.6, 0.8, 0.8, 0.8, 0.6, 0.6,\n",
      "                   0.8, 1.0, 0.6, 1.0, 1.0, 0.6, 0.8, 0.6, 0.8, 1.0, 0.6,\n",
      "                   1.0, 0.8, 0.8, 0.6, 1.0, 1.0, 0.6, 0.8, 1.0, 0.6, 1.0,\n",
      "                   1.0, 0.8, 1.0, 0.6, 0.6, 0.6, 0.6, 1.0, 0.8, 0.8, 1.0,\n",
      "                   0.6, 0.6, 1.0, 1.0, 0.6, 0.6, 1.0, 0.8, 1.0, 1.0, 0.6,\n",
      "                   1.0, 0.8, 0.6, 0.6, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6,\n",
      "                   1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.8, 0.6, 1.0, 1.0,\n",
      "                   0.8, 0.8, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 0.8, 0.6, 0.6,\n",
      "                   0.6, 1.0, 0.6, 0.6, 0.6, 1.0, 1.0, 0.8, 0.6, 0.8, 0.6,\n",
      "                   1.0, 0.6, 1.0, 0.8, 1.0, 0.6, 1.0, 0.6, 0.6, 0.8, 0.8,\n",
      "                   1.0, 0.8],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[1, 3, 2, 10, 2, 1, 2, 10, 1, 2, 1, 1, 10, 1, 5, 1, 10,\n",
      "                   1, 10, 3, 3, 5, 10, 1, 1, 5, 3, 10, 1, 2, 5, 3, 10, 3,\n",
      "                   1, 5, 3, 2, 3, 5, 3, 5, 2, 1, 1, 1, 5, 3, 2, 3, 1, 5,\n",
      "                   5, 3, 2, 1, 2, 5, 1, 3, 1, 1, 1, 10, 1, 10, 10, 10, 10,\n",
      "                   2, 2, 2, 10, 5, 2, 2, 3, 3, 10, 10, 1, 10, 2, 3, 2, 2,\n",
      "                   5, 10, 3, 10, 3, 1, 5, 2, 10, 3, 5, 1, 3, 2, 10, 3, 2,\n",
      "                   1, 2, 2, 5, 5, 3, 3, 2, 1, 2, 10, 2, 3, 10, 2, 1, 5, 1,\n",
      "                   3, 2, 2, 3, 10, 3, 1, 1, 1, 3, 3, 1, 3, 3, 1, 3, 10, 1,\n",
      "                   3, 5, 5, 1, 1, 10, 1, 1, 2, 10, 2, 3, 2, 5, 10, 1, 1,\n",
      "                   2, 10, 2, 2, 2, 1, 3, 2, 2, 1, 3, 3, 1, 10, 10, 1, 10,\n",
      "                   2, 5, 2, 10, 2, 1, 2, 10, 5, 3, 5, 1, 5, 2, 1, 1, 3, 1,\n",
      "                   1, 10, 5, 1, 10, 10, 5, 1, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[7, 10, 8, 8, 6, 10, 6, 6, 9, 10, 10, 8, 8, 7, 10, 8, 7,\n",
      "                   7, 10, 8, 8, 10, 10, 7, 9, 6, 7, 10, 10, 9, 7, 9, 8, 7,\n",
      "                   7, 7, 7, 6, 8, 9, 9, 6, 7, 8, 9, 6, 9, 9, 10, 8, 8, 9,\n",
      "                   6, 9, 8, 9, 6, 9, 8, 7, 10, 10, 10, 8, 8, 8, 9, 9, 7,\n",
      "                   8, 10, 7, 10, 10, 10, 8, 9, 10, 7, 6, 6, 9, 8, 7, 9, 6,\n",
      "                   7, 7, 10, 7, 10, 6, 9, 8, 10, 10, 10, 9, 6, 9, 10, 6,\n",
      "                   6, 10, 9, 9, 10, 8, 10, 7, 9, 9, 8, 10, 8, 7, 7, 7, 9,\n",
      "                   7, 10, 8, 9, 6, 10, 6, 10, 9, 6, 7, 9, 6, 7, 8, 6, 10,\n",
      "                   6, 8, 6, 7, 9, 8, 6, 6, 7, 9, 6, 6, 6, 6, 10, 9, 10,\n",
      "                   10, 7, 8, 6, 10, 8, 10, 8, 9, 9, 6, 6, 9, 8, 6, 8, 7,\n",
      "                   7, 7, 8, 6, 9, 9, 7, 9, 10, 10, 6, 8, 8, 8, 7, 8, 9, 9,\n",
      "                   8, 9, 6, 10, 6, 9, 8, 7, 7, 9, 10, 8],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.5, 1.5, 5, 0.5, 2, 1, 0.5, 0.1, 0.5, 1, 1.5, 1, 0.1,\n",
      "                   1, 1, 5, 0.1, 0.5, 2, 1.5, 2, 0.5, 1, 0.5, 2, 1.5, 2,\n",
      "                   0.5, 2, 2, 2, 2, 0.1, 1.5, 5, 0.5, 1.5, 0.1, 2, 5, 0.5,\n",
      "                   5, 0.5, 5, 0.1, 1.5, 0.1, 1.5, 1.5, 0.5, 5, 0.1, 2, 5,\n",
      "                   0.1, 0.1, 0.5, 5, 1.5, 0.1, 5, 1, 1, 0.1, 0.5, 2, 1.5,\n",
      "                   2, 0.5, 0.1, 1, 0.5, 2, 2, 5, 1, 1, 0.1, 1.5, 0.1, 2,\n",
      "                   2, 1, 5, 2, 2, 2, 1, 5, 5, 1, 1, 2, 2, 0.5, 0.1, 1.5,\n",
      "                   2, 2, 1.5, 2, 5, 1.5, 0.5, 1, 0.1, 1, 1, 0.1, 1.5, 0.1,\n",
      "                   1.5, 0.1, 1.5, 0.5, 1, 0.1, 2, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "                   1, 2, 5, 0.5, 2, 5, 2, 1, 1.5, 5, 1.5, 1, 0.5, 1, 1, 1,\n",
      "                   2, 1, 1, 5, 0.1, 0.5, 5, 5, 0.5, 1.5, 0.1, 0.1, 5, 5,\n",
      "                   2, 1.5, 1, 0.1, 2, 5, 2, 0.5, 0.5, 0.5, 0.5, 2, 1, 1,\n",
      "                   1.5, 1, 0.1, 5, 0.5, 0.5, 1, 5, 1.5, 0.5, 1, 1, 0.5,\n",
      "                   0.1, 0.5, 1, 2, 1.5, 1, 0.1, 1, 0.1, 1.5, 1.5, 0.5,\n",
      "                   1.5, 2, 0.5, 0.1, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_colsample_bytree': masked_array(data=[1.0, 1.0, 1.0, 0.6, 0.6, 1.0, 0.6, 1.0, 1.0, 1.0, 0.6,\n",
      "                   1.0, 0.8, 0.6, 0.8, 1.0, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6,\n",
      "                   0.8, 0.6, 0.8, 0.6, 0.8, 0.8, 1.0, 0.8, 0.8, 1.0, 0.8,\n",
      "                   0.8, 1.0, 0.8, 0.6, 0.6, 0.8, 1.0, 0.8, 1.0, 1.0, 0.8,\n",
      "                   0.8, 1.0, 0.6, 0.8, 1.0, 0.6, 0.8, 1.0, 0.8, 0.6, 0.6,\n",
      "                   0.6, 0.6, 1.0, 0.6, 0.6, 1.0, 0.6, 0.8, 1.0, 0.6, 1.0,\n",
      "                   0.6, 1.0, 0.8, 0.6, 0.6, 0.6, 0.6, 0.6, 1.0, 0.8, 0.8,\n",
      "                   1.0, 1.0, 1.0, 0.8, 0.8, 0.6, 0.8, 1.0, 1.0, 0.8, 0.6,\n",
      "                   1.0, 0.8, 0.8, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6, 0.6,\n",
      "                   0.8, 0.6, 0.8, 0.8, 0.8, 0.6, 0.6, 0.8, 0.8, 1.0, 0.8,\n",
      "                   0.6, 0.6, 0.8, 1.0, 0.8, 1.0, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
      "                   1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.8, 0.6, 1.0, 0.6,\n",
      "                   0.6, 0.8, 0.6, 0.6, 0.6, 0.6, 0.8, 1.0, 0.6, 0.6, 0.6,\n",
      "                   0.8, 0.8, 1.0, 0.8, 0.6, 0.8, 0.8, 1.0, 0.6, 1.0, 0.8,\n",
      "                   0.8, 0.6, 0.8, 1.0, 0.6, 1.0, 1.0, 1.0, 0.8, 1.0, 0.8,\n",
      "                   1.0, 0.6, 0.6, 1.0, 0.8, 0.6, 0.6, 1.0, 0.8, 0.8, 0.6,\n",
      "                   1.0, 1.0, 0.8, 0.6, 0.8, 1.0, 1.0, 1.0, 0.8, 0.6, 0.8,\n",
      "                   0.6, 1.0, 0.6, 1.0, 0.6, 0.8, 1.0, 0.8, 0.8, 0.8, 0.6,\n",
      "                   1.0, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 7, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 10, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 8, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 8, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 6, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 8, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 7, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 8, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 7, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 8, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 8, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 10, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 7, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 6, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 7, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 7, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 8, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 7, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 7, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 7, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 7, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 8, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 9, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 6, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 7, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 8, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 9, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 10, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 8, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 8, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 6, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 9, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 8, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 8, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 7, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 8, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 8, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 8, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 9, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 8, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 7, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 10, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 10, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 9, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 10, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 6, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 7, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 7, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 10, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 8, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 10, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 10, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 6, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 6, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 5, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 10, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 7, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 8, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 8, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 7, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 7, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 5, 'max_depth': 7, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 10, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 6, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 10, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 7, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 6, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 7, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 6, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 6, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 7, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 6, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 10, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 10, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 7, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 8, 'gamma': 5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 10, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 10, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 8, 'gamma': 2, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 3, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 3, 'max_depth': 8, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 6, 'gamma': 2, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 7, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 10, 'max_depth': 8, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 2, 'max_depth': 6, 'gamma': 5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 10, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 6, 'gamma': 1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 8, 'gamma': 0.5, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 8, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 7, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 2, 'max_depth': 9, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 1.5, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 8, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 3, 'max_depth': 9, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 6, 'gamma': 1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 0.1, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 6, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 1.5, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'min_child_weight': 1, 'max_depth': 8, 'gamma': 0.5, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 1.5, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 10, 'max_depth': 7, 'gamma': 2, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 9, 'gamma': 0.5, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 10, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'min_child_weight': 5, 'max_depth': 8, 'gamma': 5, 'colsample_bytree': 1.0}], 'split0_test_score': array([0.98657876, 0.97133271, 0.94825759, 0.94190016, 0.96950789,\n",
      "       0.97721921, 0.97186249, 0.95673417, 0.98292913, 0.97492348,\n",
      "       0.98775606, 0.98387097, 0.95744055, 0.97769013, 0.96456322,\n",
      "       0.95408524, 0.94372498, 0.99087591, 0.94590299, 0.96886037,\n",
      "       0.96956675, 0.96762421, 0.93895691, 0.9888745 , 0.97833765,\n",
      "       0.9603838 , 0.97180363, 0.95267247, 0.9715093 , 0.97368731,\n",
      "       0.96379798, 0.96462209, 0.94307747, 0.97233341, 0.9603838 ,\n",
      "       0.96850718, 0.97092065, 0.97975041, 0.96921356, 0.93836826,\n",
      "       0.97192136, 0.93006828, 0.97886744, 0.96244408, 0.98463621,\n",
      "       0.97339298, 0.97621851, 0.97457028, 0.97462915, 0.97633624,\n",
      "       0.96185543, 0.96473982, 0.95832352, 0.9566753 , 0.97686602,\n",
      "       0.99046386, 0.97721921, 0.93448316, 0.97510007, 0.97351071,\n",
      "       0.9568519 , 0.98316459, 0.98493054, 0.95331999, 0.98622557,\n",
      "       0.94755121, 0.9494349 , 0.9367789 , 0.95620438, 0.97980928,\n",
      "       0.97780786, 0.98322345, 0.9342477 , 0.96391571, 0.95014128,\n",
      "       0.97321639, 0.97074405, 0.97557099, 0.93966329, 0.9527902 ,\n",
      "       0.97457028, 0.94525547, 0.9775724 , 0.95702849, 0.97198022,\n",
      "       0.9701554 , 0.95850012, 0.94237109, 0.94749235, 0.93242289,\n",
      "       0.96844832, 0.98204615, 0.96220862, 0.96691782, 0.95290794,\n",
      "       0.977749  , 0.96332705, 0.97315752, 0.96315046, 0.97780786,\n",
      "       0.94655051, 0.94725689, 0.9763951 , 0.98993407, 0.97398163,\n",
      "       0.98163409, 0.96079586, 0.96356251, 0.97798446, 0.96674123,\n",
      "       0.98257594, 0.98104544, 0.98287026, 0.93983989, 0.98075112,\n",
      "       0.97092065, 0.94272428, 0.97192136, 0.98734401, 0.96050153,\n",
      "       0.9876972 , 0.97327525, 0.97321639, 0.96927243, 0.96503414,\n",
      "       0.93642571, 0.9691547 , 0.97086178, 0.95661644, 0.98493054,\n",
      "       0.96986108, 0.95744055, 0.97180363, 0.96927243, 0.97298093,\n",
      "       0.96379798, 0.96579939, 0.94119378, 0.98575465, 0.97115611,\n",
      "       0.96509301, 0.9664469 , 0.96844832, 0.98139863, 0.95131858,\n",
      "       0.95473275, 0.98204615, 0.9812809 , 0.93153991, 0.95496821,\n",
      "       0.97492348, 0.98245821, 0.97551213, 0.94307747, 0.96144337,\n",
      "       0.96344478, 0.97351071, 0.93754415, 0.97356958, 0.97980928,\n",
      "       0.97333412, 0.95702849, 0.96456322, 0.98122204, 0.98139863,\n",
      "       0.98822698, 0.97427596, 0.97221568, 0.98510713, 0.93960443,\n",
      "       0.94819873, 0.98569579, 0.95567459, 0.95614551, 0.96415117,\n",
      "       0.97562986, 0.94095832, 0.95585119, 0.97486461, 0.97615964,\n",
      "       0.94119378, 0.9642689 , 0.97492348, 0.97009654, 0.98334118,\n",
      "       0.96550506, 0.96821286, 0.98604898, 0.97939722, 0.98051566,\n",
      "       0.98004474, 0.99040499, 0.93830939, 0.96315046, 0.98098658,\n",
      "       0.93972216, 0.94590299, 0.96809513, 0.99081705, 0.95114198]), 'split1_test_score': array([0.99282353, 0.98294118, 0.96147059, 0.95758824, 0.98152941,\n",
      "       0.98911765, 0.98823529, 0.97182353, 0.99111765, 0.98547059,\n",
      "       0.992     , 0.99023529, 0.96929412, 0.98782353, 0.98364706,\n",
      "       0.95370588, 0.95758824, 0.98952941, 0.95658824, 0.98311765,\n",
      "       0.98088235, 0.98347059, 0.95376471, 0.99535294, 0.98870588,\n",
      "       0.97517647, 0.97876471, 0.96782353, 0.98511765, 0.98482353,\n",
      "       0.97394118, 0.97764706, 0.95576471, 0.98317647, 0.97      ,\n",
      "       0.98617647, 0.98388235, 0.99047059, 0.981     , 0.95347059,\n",
      "       0.98623529, 0.93088235, 0.98952941, 0.96664706, 0.99464706,\n",
      "       0.98341176, 0.98647059, 0.98582353, 0.98570588, 0.99023529,\n",
      "       0.96929412, 0.98111765, 0.97529412, 0.96611765, 0.98941176,\n",
      "       0.99752941, 0.99058824, 0.93794118, 0.98552941, 0.98764706,\n",
      "       0.95688235, 0.99205882, 0.99264706, 0.96794118, 0.99352941,\n",
      "       0.95905882, 0.96052941, 0.94947059, 0.96952941, 0.99329412,\n",
      "       0.98964706, 0.99211765, 0.94823529, 0.97758824, 0.96223529,\n",
      "       0.98741176, 0.98735294, 0.98929412, 0.95323529, 0.96929412,\n",
      "       0.98123529, 0.95282353, 0.98829412, 0.96358824, 0.97411765,\n",
      "       0.98288235, 0.97741176, 0.95452941, 0.95841176, 0.93029412,\n",
      "       0.98582353, 0.99117647, 0.97388235, 0.98      , 0.96976471,\n",
      "       0.99011765, 0.978     , 0.98347059, 0.97411765, 0.98529412,\n",
      "       0.953     , 0.95964706, 0.98470588, 0.99623529, 0.985     ,\n",
      "       0.99258824, 0.97841176, 0.983     , 0.98870588, 0.97947059,\n",
      "       0.99247059, 0.98905882, 0.99294118, 0.95229412, 0.99352941,\n",
      "       0.98094118, 0.95511765, 0.98405882, 0.99394118, 0.97894118,\n",
      "       0.99470588, 0.98      , 0.98382353, 0.97152941, 0.97858824,\n",
      "       0.94558824, 0.98182353, 0.98417647, 0.96211765, 0.99341176,\n",
      "       0.98005882, 0.95976471, 0.98311765, 0.984     , 0.98311765,\n",
      "       0.97335294, 0.97694118, 0.95458824, 0.99429412, 0.98529412,\n",
      "       0.98258824, 0.97917647, 0.97976471, 0.98894118, 0.96570588,\n",
      "       0.96594118, 0.99347059, 0.98917647, 0.93241176, 0.963     ,\n",
      "       0.98829412, 0.987     , 0.98594118, 0.95541176, 0.96405882,\n",
      "       0.96958824, 0.98235294, 0.95129412, 0.98617647, 0.996     ,\n",
      "       0.97135294, 0.96982353, 0.97664706, 0.98717647, 0.99029412,\n",
      "       0.99411765, 0.98941176, 0.98194118, 0.98588235, 0.95441176,\n",
      "       0.96041176, 0.99358824, 0.97029412, 0.96470588, 0.98017647,\n",
      "       0.98835294, 0.95494118, 0.95652941, 0.98758824, 0.98847059,\n",
      "       0.95229412, 0.97758824, 0.98652941, 0.985     , 0.99123529,\n",
      "       0.97994118, 0.98247059, 0.99282353, 0.98947059, 0.99117647,\n",
      "       0.98988235, 0.99735294, 0.94964706, 0.97288235, 0.99223529,\n",
      "       0.95088235, 0.95764706, 0.98358824, 0.99594118, 0.96152941]), 'split2_test_score': array([0.99329934, 0.98547201, 0.94675047, 0.93708491, 0.98238852,\n",
      "       0.98831831, 0.99021584, 0.97390892, 0.9915797 , 0.98760674,\n",
      "       0.9886148 , 0.99021584, 0.97639943, 0.98802182, 0.9828629 ,\n",
      "       0.94206594, 0.93868596, 0.99092742, 0.94805503, 0.98398956,\n",
      "       0.9829815 , 0.98689516, 0.93833017, 0.9941888 , 0.98541271,\n",
      "       0.97841556, 0.98215133, 0.96287951, 0.98126186, 0.9828629 ,\n",
      "       0.9745612 , 0.97349383, 0.93921964, 0.98464184, 0.9574834 ,\n",
      "       0.98719165, 0.98393027, 0.99383302, 0.98185484, 0.93085863,\n",
      "       0.9886741 , 0.93394213, 0.99057163, 0.96044829, 0.99448529,\n",
      "       0.98434535, 0.99051233, 0.98659867, 0.98618359, 0.99086812,\n",
      "       0.9573055 , 0.98274431, 0.97041034, 0.95760199, 0.99246917,\n",
      "       0.99412951, 0.99329934, 0.93785579, 0.98499763, 0.99051233,\n",
      "       0.94378558, 0.99074953, 0.99116461, 0.96620019, 0.99270636,\n",
      "       0.94823292, 0.95991461, 0.93151091, 0.97195209, 0.99460389,\n",
      "       0.98968216, 0.99205408, 0.92730076, 0.97604364, 0.94870731,\n",
      "       0.98695446, 0.98760674, 0.99027514, 0.93785579, 0.96667457,\n",
      "       0.98315939, 0.95404412, 0.98932638, 0.95137571, 0.97509488,\n",
      "       0.98268501, 0.97082543, 0.93536528, 0.94301471, 0.92706357,\n",
      "       0.98404886, 0.98974146, 0.97533207, 0.97954222, 0.96625949,\n",
      "       0.99324004, 0.97948292, 0.97883065, 0.96857211, 0.98719165,\n",
      "       0.95315465, 0.93987192, 0.98481973, 0.99383302, 0.98719165,\n",
      "       0.99495968, 0.97645873, 0.98351518, 0.99341793, 0.97859345,\n",
      "       0.99341793, 0.98831831, 0.99412951, 0.93726281, 0.99122391,\n",
      "       0.98185484, 0.93987192, 0.9830408 , 0.99169829, 0.97574715,\n",
      "       0.99199478, 0.98630218, 0.98333729, 0.96809772, 0.97230787,\n",
      "       0.92860531, 0.98470114, 0.98108397, 0.95262097, 0.99306214,\n",
      "       0.98327799, 0.95653463, 0.97924573, 0.98250712, 0.98511622,\n",
      "       0.96537002, 0.97550996, 0.93536528, 0.99341793, 0.98808112,\n",
      "       0.98464184, 0.98476044, 0.97776328, 0.99057163, 0.9602704 ,\n",
      "       0.94734345, 0.99401091, 0.99276565, 0.92558112, 0.95036765,\n",
      "       0.99063093, 0.98879269, 0.98914848, 0.93921964, 0.95955882,\n",
      "       0.96252372, 0.98102467, 0.9433112 , 0.98653937, 0.99258776,\n",
      "       0.97343454, 0.95914374, 0.97580645, 0.99128321, 0.99252846,\n",
      "       0.99300285, 0.99074953, 0.98256641, 0.99051233, 0.93583966,\n",
      "       0.96133776, 0.99252846, 0.97497628, 0.95356973, 0.9800759 ,\n",
      "       0.99063093, 0.94283681, 0.9431333 , 0.9857092 , 0.99057163,\n",
      "       0.93666983, 0.97705171, 0.98825901, 0.98956357, 0.99282495,\n",
      "       0.98321869, 0.9801352 , 0.98956357, 0.98831831, 0.99341793,\n",
      "       0.99021584, 0.99460389, 0.93275617, 0.97070683, 0.99229127,\n",
      "       0.93204459, 0.94906309, 0.98636148, 0.99460389, 0.94734345]), 'split3_test_score': array([0.99015655, 0.98938567, 0.9716556 , 0.97420541, 0.98938567,\n",
      "       0.99057163, 0.99199478, 0.97865275, 0.9914611 , 0.98991935,\n",
      "       0.99003795, 0.99033444, 0.98333729, 0.99104602, 0.98837761,\n",
      "       0.95932163, 0.97479839, 0.9885555 , 0.97539137, 0.99051233,\n",
      "       0.98671727, 0.99015655, 0.97290085, 0.99211338, 0.98956357,\n",
      "       0.98701376, 0.98535342, 0.9802538 , 0.98612429, 0.99045304,\n",
      "       0.98155835, 0.98541271, 0.97384962, 0.98636148, 0.97770398,\n",
      "       0.99051233, 0.99116461, 0.99080882, 0.98819972, 0.96839421,\n",
      "       0.99027514, 0.95481499, 0.99069023, 0.97527277, 0.99472249,\n",
      "       0.9886741 , 0.98920778, 0.98742884, 0.99009725, 0.9915204 ,\n",
      "       0.97912713, 0.98630218, 0.98357448, 0.97805977, 0.99371442,\n",
      "       0.99365512, 0.99389231, 0.95902514, 0.98974146, 0.99347723,\n",
      "       0.96074478, 0.99383302, 0.99276565, 0.98209203, 0.99401091,\n",
      "       0.97479839, 0.97408681, 0.96969877, 0.98173624, 0.99460389,\n",
      "       0.99229127, 0.99128321, 0.96946157, 0.98369307, 0.97076613,\n",
      "       0.98962287, 0.99116461, 0.98980076, 0.97058824, 0.98143975,\n",
      "       0.98535342, 0.97011385, 0.99116461, 0.97509488, 0.97580645,\n",
      "       0.98808112, 0.98487903, 0.97337524, 0.96999526, 0.9545778 ,\n",
      "       0.98819972, 0.9915204 , 0.9828629 , 0.98559061, 0.98221063,\n",
      "       0.99187619, 0.98707306, 0.98790323, 0.98618359, 0.99074953,\n",
      "       0.97497628, 0.9686314 , 0.98825901, 0.98968216, 0.99163899,\n",
      "       0.99513757, 0.98470114, 0.98814042, 0.98695446, 0.98742884,\n",
      "       0.99205408, 0.99181689, 0.9941888 , 0.97177419, 0.99003795,\n",
      "       0.98351518, 0.97319734, 0.98986006, 0.98766603, 0.98553131,\n",
      "       0.98707306, 0.98517552, 0.98920778, 0.97829696, 0.98606499,\n",
      "       0.96786053, 0.98778463, 0.98689516, 0.97296015, 0.99412951,\n",
      "       0.98624288, 0.9743833 , 0.98748814, 0.98932638, 0.98731025,\n",
      "       0.97687381, 0.98908918, 0.97254507, 0.99051233, 0.98950427,\n",
      "       0.98843691, 0.9886148 , 0.98778463, 0.9884962 , 0.97823767,\n",
      "       0.97242647, 0.99312144, 0.9915204 , 0.95517078, 0.97242647,\n",
      "       0.99169829, 0.98962287, 0.98689516, 0.97384962, 0.97349383,\n",
      "       0.9801945 , 0.98505693, 0.96655598, 0.99122391, 0.98796252,\n",
      "       0.97954222, 0.97823767, 0.98434535, 0.98897059, 0.9887334 ,\n",
      "       0.99104602, 0.99329934, 0.98671727, 0.9828629 , 0.97230787,\n",
      "       0.9774075 , 0.99039374, 0.97782258, 0.97550996, 0.98707306,\n",
      "       0.99223197, 0.97414611, 0.96228653, 0.98814042, 0.99329934,\n",
      "       0.97266366, 0.98179554, 0.98736954, 0.99098672, 0.99163899,\n",
      "       0.9886148 , 0.98736954, 0.98938567, 0.99063093, 0.99199478,\n",
      "       0.98962287, 0.9943074 , 0.97088472, 0.98090607, 0.99223197,\n",
      "       0.97212998, 0.97248577, 0.99039374, 0.98986006, 0.9744426 ]), 'split4_test_score': array([0.97835626, 0.96875   , 0.94497154, 0.92392078, 0.96513283,\n",
      "       0.97201139, 0.96892789, 0.94544592, 0.97325664, 0.96904649,\n",
      "       0.97930503, 0.97776328, 0.94692837, 0.97212998, 0.95872865,\n",
      "       0.94995256, 0.92380218, 0.97805977, 0.93062144, 0.96762334,\n",
      "       0.96904649, 0.96133776, 0.9261148 , 0.97515417, 0.97497628,\n",
      "       0.95439991, 0.97212998, 0.93530598, 0.96797913, 0.97396822,\n",
      "       0.96910579, 0.96062619, 0.92380218, 0.97888994, 0.95979602,\n",
      "       0.95920304, 0.96762334, 0.97082543, 0.9658444 , 0.93435721,\n",
      "       0.96234583, 0.93767789, 0.97064753, 0.96620019, 0.97129981,\n",
      "       0.96999526, 0.96252372, 0.97373102, 0.97485769, 0.97337524,\n",
      "       0.96098197, 0.95439991, 0.95523008, 0.96127846, 0.9716556 ,\n",
      "       0.97877135, 0.96922438, 0.93803368, 0.97118121, 0.96815702,\n",
      "       0.95013046, 0.97580645, 0.97829696, 0.93927894, 0.97562856,\n",
      "       0.93548387, 0.94473435, 0.91941414, 0.94544592, 0.97041034,\n",
      "       0.97230787, 0.97509488, 0.91828748, 0.9660223 , 0.94763994,\n",
      "       0.96714896, 0.96821632, 0.96697106, 0.92433586, 0.93809298,\n",
      "       0.97301945, 0.94461575, 0.97100332, 0.95268027, 0.96655598,\n",
      "       0.96981736, 0.95653463, 0.92380218, 0.94686907, 0.93002846,\n",
      "       0.96246442, 0.97503558, 0.96809772, 0.96418406, 0.94016841,\n",
      "       0.96904649, 0.95955882, 0.96821632, 0.95884725, 0.97379032,\n",
      "       0.94580171, 0.93613615, 0.97467979, 0.97883065, 0.96922438,\n",
      "       0.97094402, 0.94852941, 0.95878795, 0.97835626, 0.95760199,\n",
      "       0.97189279, 0.9745019 , 0.97272296, 0.92433586, 0.97912713,\n",
      "       0.97224858, 0.92504744, 0.97207068, 0.97960152, 0.94847011,\n",
      "       0.97823767, 0.97533207, 0.9743833 , 0.9630574 , 0.96003321,\n",
      "       0.91953273, 0.96643738, 0.97189279, 0.95777989, 0.97325664,\n",
      "       0.9688093 , 0.95084203, 0.96661528, 0.96323529, 0.96946157,\n",
      "       0.96471774, 0.96181214, 0.92380218, 0.97811907, 0.96845351,\n",
      "       0.96904649, 0.96519213, 0.96685247, 0.97367173, 0.93412002,\n",
      "       0.94627609, 0.97254507, 0.97224858, 0.93115512, 0.94835152,\n",
      "       0.96981736, 0.97509488, 0.96228653, 0.92380218, 0.96133776,\n",
      "       0.96471774, 0.97426471, 0.94105787, 0.97011385, 0.9800166 ,\n",
      "       0.96566651, 0.96531072, 0.95789848, 0.97639943, 0.97497628,\n",
      "       0.97693311, 0.96898719, 0.96845351, 0.96732685, 0.9261148 ,\n",
      "       0.94408207, 0.97509488, 0.94805503, 0.95060484, 0.95096063,\n",
      "       0.97011385, 0.92469165, 0.9402277 , 0.96993596, 0.96963947,\n",
      "       0.92676708, 0.96359108, 0.97527277, 0.96098197, 0.97284156,\n",
      "       0.9601518 , 0.96145636, 0.97687381, 0.97414611, 0.97023245,\n",
      "       0.97396822, 0.97746679, 0.92196395, 0.96453985, 0.97183349,\n",
      "       0.92184535, 0.9318667 , 0.9603297 , 0.9772889 , 0.94870731]), 'mean_test_score': array([0.98824289, 0.97957631, 0.95462116, 0.9469399 , 0.97758886,\n",
      "       0.98344764, 0.98224726, 0.96531306, 0.98606884, 0.98139333,\n",
      "       0.98754277, 0.98648397, 0.96667995, 0.9833423 , 0.97563589,\n",
      "       0.95182625, 0.94771995, 0.9875896 , 0.95131181, 0.97882065,\n",
      "       0.97783887, 0.97789685, 0.94601349, 0.98913676, 0.98339922,\n",
      "       0.9710779 , 0.97804061, 0.95978706, 0.97839844, 0.981159  ,\n",
      "       0.9725929 , 0.97236038, 0.94714272, 0.98108063, 0.96507344,\n",
      "       0.97831813, 0.97950424, 0.98513765, 0.9772225 , 0.94508978,\n",
      "       0.97989034, 0.93747713, 0.98406125, 0.96620248, 0.98795817,\n",
      "       0.97996389, 0.98098659, 0.98163047, 0.98229471, 0.98446706,\n",
      "       0.96571283, 0.97386077, 0.96856651, 0.96394663, 0.98482339,\n",
      "       0.99090985, 0.9848447 , 0.94146779, 0.98130996, 0.98266087,\n",
      "       0.95367901, 0.98712248, 0.98796097, 0.96176646, 0.98842016,\n",
      "       0.95302504, 0.95774002, 0.94137466, 0.96497361, 0.9865443 ,\n",
      "       0.98434725, 0.98675465, 0.93950656, 0.97345259, 0.95589799,\n",
      "       0.98087089, 0.98101693, 0.98238241, 0.94513569, 0.96165833,\n",
      "       0.97946757, 0.95337054, 0.98347217, 0.95995352, 0.97271103,\n",
      "       0.97872425, 0.96963019, 0.94588864, 0.95315663, 0.93487737,\n",
      "       0.97779697, 0.98590401, 0.97247673, 0.97524694, 0.96226223,\n",
      "       0.98440587, 0.97348837, 0.97831566, 0.97017421, 0.9829667 ,\n",
      "       0.95469663, 0.95030868, 0.9817719 , 0.98970304, 0.98140733,\n",
      "       0.98705272, 0.96977938, 0.97540121, 0.9850838 , 0.97396722,\n",
      "       0.98648226, 0.98494827, 0.98737054, 0.94510137, 0.9869339 ,\n",
      "       0.97789608, 0.94719172, 0.98019034, 0.98805021, 0.96983826,\n",
      "       0.98794172, 0.98001701, 0.98079366, 0.97005079, 0.97240569,\n",
      "       0.9396025 , 0.97798028, 0.97898203, 0.96041902, 0.98775812,\n",
      "       0.97765001, 0.95979304, 0.97765408, 0.97766824, 0.97959732,\n",
      "       0.9688225 , 0.97383037, 0.94549891, 0.98841962, 0.98049783,\n",
      "       0.9779613 , 0.97683815, 0.97612268, 0.98461587, 0.95793051,\n",
      "       0.95734399, 0.98703883, 0.9853984 , 0.93517174, 0.95782277,\n",
      "       0.98307284, 0.98459373, 0.97995669, 0.94707213, 0.96397852,\n",
      "       0.9680938 , 0.97924199, 0.94795266, 0.98152464, 0.98727523,\n",
      "       0.97266606, 0.96590883, 0.97185211, 0.98501035, 0.98558618,\n",
      "       0.98866532, 0.98334476, 0.97837881, 0.98233831, 0.94565571,\n",
      "       0.95828756, 0.98746022, 0.96536452, 0.96010719, 0.97248744,\n",
      "       0.98339191, 0.94751481, 0.95160563, 0.98124768, 0.98362813,\n",
      "       0.94591769, 0.97285909, 0.98247084, 0.97932576, 0.9863764 ,\n",
      "       0.97548631, 0.97592891, 0.98693911, 0.98439263, 0.98546746,\n",
      "       0.9847468 , 0.9908272 , 0.94271226, 0.97043711, 0.98591572,\n",
      "       0.94332489, 0.95139312, 0.97775366, 0.98970221, 0.95663295]), 'std_test_score': array([0.00549048, 0.00809285, 0.01032129, 0.01737351, 0.00892395,\n",
      "       0.00743243, 0.00979406, 0.01234928, 0.00719648, 0.00802779,\n",
      "       0.00436229, 0.00501405, 0.01307104, 0.00719708, 0.01172364,\n",
      "       0.00571999, 0.01732199, 0.00484674, 0.0146671 , 0.00901625,\n",
      "       0.00721484, 0.01133196, 0.01604866, 0.00732947, 0.00577545,\n",
      "       0.0119759 , 0.00538024, 0.01511937, 0.00733564, 0.00648452,\n",
      "       0.00592591, 0.00891257, 0.01680285, 0.00502544, 0.00763223,\n",
      "       0.01225425, 0.00882673, 0.00860318, 0.00836459, 0.01397302,\n",
      "       0.01092311, 0.00907216, 0.00803906, 0.00509321, 0.00918299,\n",
      "       0.00706404, 0.01050728, 0.00613406, 0.00635152, 0.00791372,\n",
      "       0.00775516, 0.01223344, 0.01055158, 0.00779923, 0.00889125,\n",
      "       0.00646937, 0.00988404, 0.00888057, 0.00698065, 0.00997585,\n",
      "       0.00601209, 0.00672713, 0.00561933, 0.01447719, 0.00698819,\n",
      "       0.01319928, 0.01017693, 0.01713755, 0.01271747, 0.00980958,\n",
      "       0.0078405 , 0.00671972, 0.01789067, 0.00741412, 0.00910235,\n",
      "       0.00898079, 0.00954917, 0.00947633, 0.01567809, 0.01489122,\n",
      "       0.00483651, 0.00920426, 0.00783551, 0.00868915, 0.00333652,\n",
      "       0.00739305, 0.01086168, 0.01697705, 0.00985527, 0.00999705,\n",
      "       0.01033647, 0.00643544, 0.00696579, 0.00824371, 0.01446267,\n",
      "       0.00945195, 0.01037418, 0.00703368, 0.00950842, 0.00623953,\n",
      "       0.01060188, 0.01218218, 0.00527614, 0.0059664 , 0.00842161,\n",
      "       0.00945916, 0.01322161, 0.01184922, 0.00602888, 0.01051608,\n",
      "       0.00828397, 0.00632124, 0.00846178, 0.01602191, 0.00584316,\n",
      "       0.00523583, 0.01614323, 0.00708376, 0.00489977, 0.01347458,\n",
      "       0.0056065 , 0.00516747, 0.00608203, 0.00497018, 0.00929761,\n",
      "       0.01654189, 0.00856966, 0.00648404, 0.00696275, 0.00798723,\n",
      "       0.00707304, 0.00786319, 0.00755216, 0.00977975, 0.00705479,\n",
      "       0.00527945, 0.00953167, 0.01676951, 0.00595106, 0.00887649,\n",
      "       0.00917435, 0.00949239, 0.00770441, 0.00631445, 0.01475784,\n",
      "       0.01030263, 0.00850849, 0.00769286, 0.01028477, 0.00887134,\n",
      "       0.00895438, 0.00535728, 0.01000434, 0.01676719, 0.00496955,\n",
      "       0.00652223, 0.00456706, 0.01034086, 0.00817743, 0.00653062,\n",
      "       0.00445054, 0.00764604, 0.00940788, 0.0054447 , 0.00648645,\n",
      "       0.00619752, 0.00978893, 0.00687389, 0.00790772, 0.01613584,\n",
      "       0.01168733, 0.00675071, 0.01153606, 0.00902354, 0.01313273,\n",
      "       0.00885119, 0.01643256, 0.0084568 , 0.00743393, 0.00912858,\n",
      "       0.01568815, 0.0074765 , 0.00604561, 0.01178695, 0.0075537 ,\n",
      "       0.01083296, 0.00959549, 0.00546996, 0.00648164, 0.00888858,\n",
      "       0.00660829, 0.0070376 , 0.01667801, 0.00638003, 0.00828354,\n",
      "       0.01725366, 0.01342284, 0.01153074, 0.00660771, 0.01020216]), 'rank_test_score': array([  9,  85, 167, 183, 108,  52,  64, 146,  30,  69,  16,  27, 141,\n",
      "        56, 113, 172, 178,  15, 175,  91, 102, 100, 184,   5,  53, 131,\n",
      "        97, 158,  93,  72, 125, 129, 181,  73, 147,  95,  86,  36, 109,\n",
      "       191,  83, 198,  49, 142,  12,  81,  75,  66,  63,  45, 144, 118,\n",
      "       139, 150,  41,   1,  40, 194,  70,  59, 168,  20,  11, 152,   7,\n",
      "       171, 162, 195, 148,  26,  48,  25, 197, 121, 165,  76,  74,  61,\n",
      "       189, 153,  87, 169,  51, 156, 123,  92, 137, 186, 170, 200, 103,\n",
      "        32, 127, 116, 151,  46, 120,  96, 133,  58, 166, 176,  65,   3,\n",
      "        68,  21, 136, 115,  37, 117,  28,  39,  18, 190,  24, 101, 180,\n",
      "        79,  10, 135,  13,  80,  77, 134, 128, 196,  98,  90, 154,  14,\n",
      "       107, 157, 106, 105,  84, 138, 119, 188,   8,  78,  99, 110, 111,\n",
      "        43, 160, 163,  22,  35, 199, 161,  57,  44,  82, 182, 149, 140,\n",
      "        89, 177,  67,  19, 124, 143, 130,  38,  33,   6,  55,  94,  62,\n",
      "       187, 159,  17, 145, 155, 126,  54, 179, 173,  71,  50, 185, 122,\n",
      "        60,  88,  29, 114, 112,  23,  47,  34,  42,   2, 193, 132,  31,\n",
      "       192, 174, 104,   4, 164])}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.6, gamma=0.1,\n",
      "              learning_rate=0.02, max_delta_step=0, max_depth=9,\n",
      "              min_child_weight=1, missing=None, n_estimators=2000, n_jobs=1,\n",
      "              nthread=1, objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=True, subsample=1.0, verbosity=1)\n",
      "\n",
      " Best normalized gini score for 5-fold search with 200 parameter combinations:\n",
      "0.9818196983337721\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 1.0, 'min_child_weight': 1, 'max_depth': 9, 'gamma': 0.1, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)\n",
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "results.to_csv('xgb-random-grid-search-results-01.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.6, gamma=0.1,\n",
    "              learning_rate=0.02, max_delta_step=0, max_depth=9,\n",
    "              min_child_weight=1, missing=None, n_estimators=2000, n_jobs=1,\n",
    "              nthread=1, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=True, subsample=1.0, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, gamma=0.1,\n",
       "              learning_rate=0.02, max_delta_step=0, max_depth=9,\n",
       "              min_child_weight=1, missing=None, n_estimators=2000, n_jobs=1,\n",
       "              nthread=1, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=True, subsample=1.0, verbosity=1)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9662576687116564"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9660493827160495"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['BusinessTravel'] = labelencoder.fit_transform(df_test['BusinessTravel'])\n",
    "df_test['Department'] = labelencoder.fit_transform(df_test['Department'])\n",
    "df_test['EducationField'] = labelencoder.fit_transform(df_test['EducationField'])\n",
    "df_test['Gender'] = labelencoder.fit_transform(df_test['Gender'])\n",
    "df_test['JobRole'] = labelencoder.fit_transform(df_test['JobRole'])\n",
    "df_test['MaritalStatus'] = labelencoder.fit_transform(df_test['MaritalStatus'])\n",
    "df_test['OverTime'] = labelencoder.fit_transform(df_test['OverTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['Id', 'Gender', 'EmployeeNumber', 'Behaviour', 'PercentSalaryHike', 'PerformanceRating'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.Series(model.predict_proba(df_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv(\"sub24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
